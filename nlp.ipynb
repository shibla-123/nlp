{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57b2c126-4501-4ada-81ba-1bee26221e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e556f5a-be25-400b-bbfb-8d7f8008550d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\AP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfa70d3a-119b-4a83-acf5-da24e80e0202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i seriously hate one subject to death but now ...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im so full of life i feel appalled</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i sit here to write i start to dig out my feel...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ive been really angry with r and i feel like a...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i feel suspicious if there is no one outside l...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5932</th>\n",
       "      <td>i begun to feel distressed for you</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5933</th>\n",
       "      <td>i left feeling annoyed and angry thinking that...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5934</th>\n",
       "      <td>i were to ever get married i d have everything...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5935</th>\n",
       "      <td>i feel reluctant in applying there because i w...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5936</th>\n",
       "      <td>i just wanted to apologize to you because i fe...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5937 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Comment Emotion\n",
       "0     i seriously hate one subject to death but now ...    fear\n",
       "1                    im so full of life i feel appalled   anger\n",
       "2     i sit here to write i start to dig out my feel...    fear\n",
       "3     ive been really angry with r and i feel like a...     joy\n",
       "4     i feel suspicious if there is no one outside l...    fear\n",
       "...                                                 ...     ...\n",
       "5932                 i begun to feel distressed for you    fear\n",
       "5933  i left feeling annoyed and angry thinking that...   anger\n",
       "5934  i were to ever get married i d have everything...     joy\n",
       "5935  i feel reluctant in applying there because i w...    fear\n",
       "5936  i just wanted to apologize to you because i fe...   anger\n",
       "\n",
       "[5937 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"nlp_dataset.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ccfd6da-fa6a-4d7a-956c-4fecd3867463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       i seriously hate one subject to death but now ...\n",
       "1                      im so full of life i feel appalled\n",
       "2       i sit here to write i start to dig out my feel...\n",
       "3       ive been really angry with r and i feel like a...\n",
       "4       i feel suspicious if there is no one outside l...\n",
       "                              ...                        \n",
       "5932                   i begun to feel distressed for you\n",
       "5933    i left feeling annoyed and angry thinking that...\n",
       "5934    i were to ever get married i d have everything...\n",
       "5935    i feel reluctant in applying there because i w...\n",
       "5936    i just wanted to apologize to you because i fe...\n",
       "Name: cleaned_text, Length: 5937, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "# Apply cleaning\n",
    "data['cleaned_text'] = data['Comment'].apply(clean_text)\n",
    "data['cleaned_text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d12488df-7624-474d-909a-141511efa0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       i seriously hate one subject to death but now ...\n",
       "1                      im so full of life i feel appalled\n",
       "2       i sit here to write i start to dig out my feel...\n",
       "3       ive been really angry with r and i feel like a...\n",
       "4       i feel suspicious if there is no one outside l...\n",
       "                              ...                        \n",
       "5932                   i begun to feel distressed for you\n",
       "5933    i left feeling annoyed and angry thinking that...\n",
       "5934    i were to ever get married i d have everything...\n",
       "5935    i feel reluctant in applying there because i w...\n",
       "5936    i just wanted to apologize to you because i fe...\n",
       "Name: Cleaned_Comment, Length: 5937, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()  # Convert text to lowercase\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    return text\n",
    "\n",
    "# Apply text cleaning\n",
    "data['Cleaned_Comment'] = data['Comment'].apply(clean_text)\n",
    "data['Cleaned_Comment'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55b871bb-421e-4e63-b14f-b0e926e163c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization function\n",
    "def tokenize_text(text):\n",
    "    tokens = word_tokenize(text)  # Tokenize the text into words\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afd736be-523b-4ad1-a23d-8fbf6a9ba0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Comment  \\\n",
      "0  i seriously hate one subject to death but now ...   \n",
      "1                 im so full of life i feel appalled   \n",
      "2  i sit here to write i start to dig out my feel...   \n",
      "3  ive been really angry with r and i feel like a...   \n",
      "4  i feel suspicious if there is no one outside l...   \n",
      "\n",
      "                                     Cleaned_Comment  \\\n",
      "0  i seriously hate one subject to death but now ...   \n",
      "1                 im so full of life i feel appalled   \n",
      "2  i sit here to write i start to dig out my feel...   \n",
      "3  ive been really angry with r and i feel like a...   \n",
      "4  i feel suspicious if there is no one outside l...   \n",
      "\n",
      "                                              Tokens  \n",
      "0  [i, seriously, hate, one, subject, to, death, ...  \n",
      "1        [im, so, full, of, life, i, feel, appalled]  \n",
      "2  [i, sit, here, to, write, i, start, to, dig, o...  \n",
      "3  [ive, been, really, angry, with, r, and, i, fe...  \n",
      "4  [i, feel, suspicious, if, there, is, no, one, ...  \n"
     ]
    }
   ],
   "source": [
    "# Apply tokenization\n",
    "data['Tokens'] = data['Cleaned_Comment'].apply(tokenize_text)\n",
    "\n",
    "# Display the first few rows after tokenization\n",
    "print(data[['Comment', 'Cleaned_Comment', 'Tokens']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9784e1d-da2f-439a-a87c-68d0973bd0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization function\n",
    "from nltk.tokenize import sent_tokenize\n",
    "def sen_tokenize_text(text):\n",
    "    tokens = sent_tokenize(text)  # Tokenize the text into words\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a15a3fc-bd31-493e-8a1b-c49bb6c4ea0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Comment  \\\n",
      "0  i seriously hate one subject to death but now ...   \n",
      "1                 im so full of life i feel appalled   \n",
      "2  i sit here to write i start to dig out my feel...   \n",
      "3  ive been really angry with r and i feel like a...   \n",
      "4  i feel suspicious if there is no one outside l...   \n",
      "\n",
      "                                     Cleaned_Comment  \\\n",
      "0  i seriously hate one subject to death but now ...   \n",
      "1                 im so full of life i feel appalled   \n",
      "2  i sit here to write i start to dig out my feel...   \n",
      "3  ive been really angry with r and i feel like a...   \n",
      "4  i feel suspicious if there is no one outside l...   \n",
      "\n",
      "                                              Tokens  \n",
      "0  [i seriously hate one subject to death but now...  \n",
      "1               [im so full of life i feel appalled]  \n",
      "2  [i sit here to write i start to dig out my fee...  \n",
      "3  [ive been really angry with r and i feel like ...  \n",
      "4  [i feel suspicious if there is no one outside ...  \n"
     ]
    }
   ],
   "source": [
    "data['Tokens'] = data['Cleaned_Comment'].apply(sen_tokenize_text)\n",
    "\n",
    "# Display the first few rows after tokenization\n",
    "print(data[['Comment', 'Cleaned_Comment', 'Tokens']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78ef1aa9-1ae1-4895-9711-ac782f7609d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\AP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc3056cb-7067-4aba-840f-a54541f171ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [seriously, hate, one, subject, death, feel, r...\n",
       "1                        [im, full, life, feel, appalled]\n",
       "2       [sit, write, start, dig, feelings, think, afra...\n",
       "3       [ive, really, angry, r, feel, like, idiot, tru...\n",
       "4       [feel, suspicious, one, outside, like, rapture...\n",
       "                              ...                        \n",
       "5932                            [begun, feel, distressed]\n",
       "5933    [left, feeling, annoyed, angry, thinking, cent...\n",
       "5934    [ever, get, married, everything, ready, offer,...\n",
       "5935    [feel, reluctant, applying, want, able, find, ...\n",
       "5936    [wanted, apologize, feel, like, heartless, bitch]\n",
       "Name: Tokens, Length: 5937, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "text=data['Comment']\n",
    "# Tokenization and stopwords removal function\n",
    "def tokenize_and_remove_stopwords(text):\n",
    "    tokens = word_tokenize(text)  # Tokenize the text into words\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]  # Remove stopwords\n",
    "    return filtered_tokens\n",
    "# Apply tokenization and stopwords removal\n",
    "data['Tokens'] = data['Cleaned_Comment'].apply(tokenize_and_remove_stopwords)\n",
    "\n",
    "\n",
    "data['Tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "074b2b39-7fe1-4758-86f0-360a9b16bb2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3f5a611-f324-4e9b-b814-da9c399d037e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Names: ['cleaned_comment' 'cleaned_text' 'comment' 'emotion' 'tokens']\n",
      "Dense Matrix:\n",
      " [[0 0 1 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 1 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Initialize CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the documents\n",
    "X = vectorizer.fit_transform(data)\n",
    "# Convert to dense array for display\n",
    "X_dense = X.toarray()\n",
    "\n",
    "# Get feature names (vocabulary)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "print(\"Feature Names:\", feature_names)\n",
    "print(\"Dense Matrix:\\n\", X_dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c0fe63-7ccc-49c4-aab9-8b2bbf9f3fba",
   "metadata": {},
   "source": [
    "#### Naive Bayes and SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63dd8687-8cd1-49b9-9af2-0054f0dcf1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Model Accuracy: 0.9006734006734006\n",
      "Naive Bayes Model Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.87      0.94      0.90       392\n",
      "        fear       0.92      0.89      0.90       416\n",
      "         joy       0.91      0.88      0.90       380\n",
      "\n",
      "    accuracy                           0.90      1188\n",
      "   macro avg       0.90      0.90      0.90      1188\n",
      "weighted avg       0.90      0.90      0.90      1188\n",
      "\n",
      "Naive Bayes Model Confusion Matrix:\n",
      " [[368  14  10]\n",
      " [ 26 369  21]\n",
      " [ 30  17 333]]\n",
      "\n",
      "Support Vector Machine (SVM) Model Accuracy: 0.936026936026936\n",
      "SVM Model Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.91      0.94      0.92       392\n",
      "        fear       0.97      0.91      0.94       416\n",
      "         joy       0.93      0.96      0.94       380\n",
      "\n",
      "    accuracy                           0.94      1188\n",
      "   macro avg       0.94      0.94      0.94      1188\n",
      "weighted avg       0.94      0.94      0.94      1188\n",
      "\n",
      "SVM Model Confusion Matrix:\n",
      " [[368   6  18]\n",
      " [ 26 380  10]\n",
      " [ 10   6 364]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the text data into numerical features\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(data['Comment'])\n",
    "\n",
    "# Extract the labels\n",
    "labels = data['Emotion']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Naive Bayes model\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with the Naive Bayes model\n",
    "nb_predictions = nb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the Naive Bayes model\n",
    "print(\"Naive Bayes Model Accuracy:\", accuracy_score(y_test, nb_predictions))\n",
    "print(\"Naive Bayes Model Classification Report:\\n\", classification_report(y_test, nb_predictions))\n",
    "print(\"Naive Bayes Model Confusion Matrix:\\n\", confusion_matrix(y_test, nb_predictions))\n",
    "\n",
    "# Train a Support Vector Machine (SVM) model\n",
    "svm_model = SVC(kernel='linear')  # Using a linear kernel for simplicity\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with the SVM model\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the SVM model\n",
    "print(\"\\nSupport Vector Machine (SVM) Model Accuracy:\", accuracy_score(y_test, svm_predictions))\n",
    "print(\"SVM Model Classification Report:\\n\", classification_report(y_test, svm_predictions))\n",
    "print(\"SVM Model Confusion Matrix:\\n\", confusion_matrix(y_test, svm_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c654459-45e1-4323-adbc-9b578bd1d3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Model:\n",
      "Accuracy: 0.9007\n",
      "F1-Score: 0.9006\n",
      "\n",
      "Support Vector Machine (SVM) Model:\n",
      "Accuracy: 0.9360\n",
      "F1-Score: 0.9361\n",
      "\n",
      "Naive Bayes Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.87      0.94      0.90       392\n",
      "        fear       0.92      0.89      0.90       416\n",
      "         joy       0.91      0.88      0.90       380\n",
      "\n",
      "    accuracy                           0.90      1188\n",
      "   macro avg       0.90      0.90      0.90      1188\n",
      "weighted avg       0.90      0.90      0.90      1188\n",
      "\n",
      "SVM Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.91      0.94      0.92       392\n",
      "        fear       0.97      0.91      0.94       416\n",
      "         joy       0.93      0.96      0.94       380\n",
      "\n",
      "    accuracy                           0.94      1188\n",
      "   macro avg       0.94      0.94      0.94      1188\n",
      "weighted avg       0.94      0.94      0.94      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "\n",
    "# Evaluate Naive Bayes model\n",
    "nb_accuracy = accuracy_score(y_test, nb_predictions)\n",
    "nb_f1_score = f1_score(y_test, nb_predictions, average='weighted')  # Weighted average for multi-class classification\n",
    "\n",
    "# Evaluate SVM model\n",
    "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "svm_f1_score = f1_score(y_test, svm_predictions, average='weighted')  # Weighted average for multi-class classification\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Naive Bayes Model:\")\n",
    "print(f\"Accuracy: {nb_accuracy:.4f}\")\n",
    "print(f\"F1-Score: {nb_f1_score:.4f}\")\n",
    "\n",
    "print(\"\\nSupport Vector Machine (SVM) Model:\")\n",
    "print(f\"Accuracy: {svm_accuracy:.4f}\")\n",
    "print(f\"F1-Score: {svm_f1_score:.4f}\")\n",
    "\n",
    "# Detailed classification reports\n",
    "print(\"\\nNaive Bayes Classification Report:\\n\", classification_report(y_test, nb_predictions))\n",
    "print(\"SVM Classification Report:\\n\", classification_report(y_test, svm_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abf8872-f343-4958-b100-ef9042a26907",
   "metadata": {},
   "source": [
    "###### Naive Bayes is suitable when you need a fast and interpretable model. It performs well with less computational resources and is effective for problems where feature independence is a reasonable assumption. However, it might struggle with more complex relationships between features.\n",
    "\n",
    "###### SVM is generally more powerful and can handle complex relationships between features better. It is particularly suited for cases where the emotion classes are not linearly separable. SVM tends to perform better on more complex or larger datasets, though it requires more computational power.\n",
    "###### If accuracy and simplicity are your primary concerns, Naive Bayes might be the preferred choice.\n",
    "###### If we need more robust performance, especially in complex scenarios, SVM may be better, provided you have the computational resources to train and tune the model.\n",
    "###### here,accuracy and f1 score little higher is for svm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73abc830-6d2c-41fd-b123-11e6d6d9ca07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
